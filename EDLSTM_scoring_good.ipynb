{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDLSTM_scoring_good.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/shinchan75034/LSTM_TouchPoint/blob/master/EDLSTM_scoring_good.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "x-maoUSy2eIG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "85b954f2-591f-4efe-a977-ddb242f5317f"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D9VoPemK2qON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c5acad79-ca26-4dc8-8f36-87eba162140d"
      },
      "cell_type": "code",
      "source": [
        "# Authenticate to GCS.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oidEUmRl2sac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6e1800ac-126f-4a2f-a39b-c7422450e3b9"
      },
      "cell_type": "code",
      "source": [
        "project_id = 'project1'"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "metadata": {
        "id": "REwICuPN28Gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3e065e7b-4b76-4e7a-8563-a75ce30bdb40"
      },
      "cell_type": "code",
      "source": [
        "# Create the service client.\n",
        "from googleapiclient.discovery import build\n",
        "gcs_service = build('storage', 'v1')\n",
        "\n",
        "from apiclient.http import MediaIoBaseDownload"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XCPXwpkI2vdi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6ddf6f6-885d-4ae4-bada-bfec3f90d651"
      },
      "cell_type": "code",
      "source": [
        "# Copy raw data from bucket to /tmp directory\n",
        "bucket_name = 'bucket-kctung75034-1'\n",
        "file_name = 'small_train_data.csv'\n",
        "path_and_file = '/tmp/'+file_name\n",
        "\n",
        "with open(path_and_file, 'wb') as f:\n",
        "  # Download the file from a given Google Cloud Storage bucket.\n",
        "  request = gcs_service.objects().get_media(bucket=bucket_name,\n",
        "                                            object=file_name)\n",
        "  media = MediaIoBaseDownload(f, request)\n",
        "\n",
        "  done = False\n",
        "  while not done:\n",
        "    # _ is a placeholder for a progress object that we ignore.\n",
        "    # (Our file is small, so we skip reporting progress.)\n",
        "    _, done = media.next_chunk()        \n",
        "  \n",
        "print('Download complete')"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UO_FMCDr204m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "75b35951-6d21-457b-c5d2-c11ac995bbb0"
      },
      "cell_type": "code",
      "source": [
        "# Read and split raw data\n",
        "from sklearn.cross_validation import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "data_path = path_and_file\n",
        "\n",
        "# Vectorize the data.\n",
        "\n",
        "with open(data_path, 'r') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "    data = np.array(lines)\n",
        "    \n",
        "    train_dat ,remained = train_test_split(data,test_size=0.4) \n",
        "    validation_dat, test_dat = train_test_split(remained, test_size = 0.5)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f5ByFkVK5njb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a07ac822-d1bd-4855-fe25-896c97c51cec"
      },
      "cell_type": "code",
      "source": [
        "# convert split data back to list\n",
        "train_lines = list(train_dat)\n",
        "validation_lines = list(validation_dat)\n",
        "test_lines = list(test_dat)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q9fkeKVI6ZOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b0fca334-7eef-40ee-9c53-4bf4b360a632"
      },
      "cell_type": "code",
      "source": [
        "# Set up all data to build a corpus\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_words = set()\n",
        "target_words = set()\n",
        "\n",
        "for line in lines:\n",
        "  try:\n",
        "    _, input_text, target_text = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '<start>' + \" \" + target_text + \" \" + '<stop>'   \n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for word in input_text.split():\n",
        "        if word not in input_words:\n",
        "            input_words.add(word)\n",
        "    for word in target_text.split():\n",
        "        if word not in target_words:\n",
        "            target_words.add(word)\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AOiaHL6M8x87",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9ccf0a3d-c3ab-4639-e98e-91cca654d309"
      },
      "cell_type": "code",
      "source": [
        "# Build the corpus.\n",
        "# sort word list, 0 reserves for unknown.\n",
        "vocab = list(set(input_words).union(set(target_words)))\n",
        "#vocab.insert(0, \"out_of_vocab\")\n",
        "#vocab.insert(0, \"\\t\")\n",
        "#vocab.insert(0, \"\\n\")\n"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p6RCdmgk-YYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cca0350c-162c-40fe-f313-d263f9bbc6e9"
      },
      "cell_type": "code",
      "source": [
        "def create_corpus_dict(word_list):\n",
        "  token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(word_list)])\n",
        "  return token_index"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jho5te6X5XHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ba3f4218-0911-443c-dece-c873397adbaf"
      },
      "cell_type": "code",
      "source": [
        "corpus_dict = create_corpus_dict(vocab)"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUM6eK-X5cFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bc77b535-1063-4d90-8f61-583c4e14e6be"
      },
      "cell_type": "code",
      "source": [
        "def split_input_and_target(line_list):\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "    \n",
        "    try:\n",
        "\n",
        "        for line in line_list:\n",
        "            _, input_text, target_text = line.split('\\t')\n",
        "            # We use \"tab\" as the \"start sequence\" character\n",
        "            # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "            target_text = '<start>' + \" \" + target_text + \" \" + '<stop>' \n",
        "            input_texts.append(input_text)\n",
        "            target_texts.append(target_text)\n",
        "            \n",
        "    except:\n",
        "      pass\n",
        "    \n",
        "    return input_texts, target_texts"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jRp5J2f5XB15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c638174c-0624-4c26-feb2-91d1122313c1"
      },
      "cell_type": "code",
      "source": [
        "# split each set of lines into input and target separately.\n",
        "train_input_texts, train_target_texts  = split_input_and_target(train_lines)\n",
        "validation_input_texts, validation_target_texts  = split_input_and_target(validation_lines)\n",
        "test_input_texts, test_target_texts  = split_input_and_target(test_lines)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vzrXm2d4X8YU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "93569e9a-c835-43fb-a372-8082afabf049"
      },
      "cell_type": "code",
      "source": [
        "def get_array_specs(input_texts,target_texts, input_vocab, target_vocab):\n",
        "    \n",
        "    # input and target may have different vocab and different token count.\n",
        "    input_vocab = sorted(list(input_vocab))\n",
        "    target_vocab = sorted(list(target_vocab))\n",
        "    num_encoder_tokens = len(input_vocab)\n",
        "    num_decoder_tokens = len(target_vocab)\n",
        "    max_encoder_seq_length = max([len(txt.split()) for txt in input_texts]) # number of words in each string.\n",
        "    max_decoder_seq_length = max([len(txt.split()) for txt in target_texts])\n",
        "    \n",
        "    return num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xd0KFqOIXGyB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c1436287-486c-4b64-f379-a1ef430f7d1d"
      },
      "cell_type": "code",
      "source": [
        "# input and target use same vocab corpus.\n",
        "num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length = get_array_specs(train_input_texts,train_target_texts, vocab, vocab)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7bDGbiU9XIqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2f5433c-805b-4297-cd00-3190245ea3f0"
      },
      "cell_type": "code",
      "source": [
        "num_encoder_tokens"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "metadata": {
        "id": "6rJsjSIPYRPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4429fb5f-3c37-4165-c00b-2457d0e10134"
      },
      "cell_type": "code",
      "source": [
        "num_decoder_tokens"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "metadata": {
        "id": "MgjaaKBWYSr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "207c9697-4618-46f3-cac5-227c6a52e449"
      },
      "cell_type": "code",
      "source": [
        "#create zero-hot holder for input text list\n",
        "import numpy as np\n",
        "\n",
        "def create_zero_hot_holder(input_texts, max_encoder_seq_length, max_decoder_seq_length,num_encoder_tokens,num_decoder_tokens):\n",
        "  encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "  decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "  decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "            \n",
        "  return encoder_input_data, decoder_input_data, decoder_target_data"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FRn35askYqJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "67cabc30-43b6-4e77-83c5-4bf4f1a0f026"
      },
      "cell_type": "code",
      "source": [
        "encoder_input_data_zero, decoder_input_data_zero, decoder_target_data_zero = create_zero_hot_holder(train_input_texts, max_encoder_seq_length, max_decoder_seq_length, num_encoder_tokens,num_decoder_tokens)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AKkXMYdCYs8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "cf14c322-366a-4946-c1bb-c4ac995bf728"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "latent_dim = 256 \n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LNGFBELjYxTv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d30a2127-467a-4aa1-8bf8-4cafd6df38df"
      },
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(encoder_input_data, decoder_input_data, decoder_target_data, input_texts, target_texts, input_corpus, target_corpus):\n",
        "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "        for t, word in enumerate(input_text.split()):\n",
        "            encoder_input_data[i, t, input_corpus[word]] = 1.\n",
        "        for t, word in enumerate(target_text.split()):\n",
        "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "            decoder_input_data[i, t, target_corpus[word]] = 1.\n",
        "            if t > 0:\n",
        "                # decoder_target_data will be ahead by one timestep\n",
        "                # and will not include the start character.\n",
        "                decoder_target_data[i, t - 1, target_corpus[word]] = 1.\n",
        "                \n",
        "    return encoder_input_data, decoder_input_data, decoder_target_data"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IeWaQrFWY3-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bd243a6f-ac6a-44a2-c082-90d0cd2f725e"
      },
      "cell_type": "code",
      "source": [
        "encoder_input_data, decoder_input_data, decoder_target_data = one_hot_encoding(encoder_input_data_zero, decoder_input_data_zero, decoder_target_data_zero, train_input_texts, train_target_texts, corpus_dict, corpus_dict)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VJes689zY7Nx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f3be2855-3b97-445d-c608-cb051bb3f7cc"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YWGFo8AkZAAk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b3ded2fd-9a2f-48dc-88ec-e1bbe7195c28"
      },
      "cell_type": "code",
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pa-_jZIUZGXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9589d911-c109-42f9-c51c-37298d8d7477"
      },
      "cell_type": "code",
      "source": [
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v846wv_5ZWT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "83d5da09-5863-4a0d-e1c4-c22b34f4c005"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, None, 46)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           (None, None, 46)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, 256), (None, 310272      input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   [(None, None, 256),  310272      input_10[0][0]                   \n",
            "                                                                 lstm_5[0][1]                     \n",
            "                                                                 lstm_5[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 46)     11822       lstm_6[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 632,366\n",
            "Trainable params: 632,366\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JjLhO_eMZbsU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "3d928540-172a-4c15-9da5-47ae9522c50b"
      },
      "cell_type": "code",
      "source": [
        "epoch_num = 10\n",
        "batch_size_num = 64\n",
        "import time\n",
        "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "print(timestr)\n",
        "model_name = 'ed_lstm_'+timestr\n",
        "print(model_name)\n",
        "model_structure = '/tmp/' + model_name + '.json'\n",
        "model_weights = '/tmp/' + model_name + '.h5'\n",
        "model_checkpoint = '/tmp/' + model_name + '_ckpt.h5'\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(model_checkpoint, monitor='val_acc', verbose=1,\n",
        "save_best_only=True, mode='min')\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size_num,\n",
        "          epochs=epoch_num,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[checkpoint], verbose=2)\n",
        "\n",
        "# Save model\n",
        "model.save('/tmp/'+ model_name)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20180708-224041\n",
            "ed_lstm_20180708-224041\n",
            "Train on 9630 samples, validate on 2408 samples\n",
            "Epoch 1/10\n",
            " - 12s - loss: 0.6470 - val_loss: 0.5789\n",
            "Epoch 2/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:435: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " - 10s - loss: 0.5766 - val_loss: 0.5700\n",
            "Epoch 3/10\n",
            " - 10s - loss: 0.5653 - val_loss: 0.5628\n",
            "Epoch 4/10\n",
            " - 11s - loss: 0.5585 - val_loss: 0.5576\n",
            "Epoch 5/10\n",
            " - 11s - loss: 0.5537 - val_loss: 0.5464\n",
            "Epoch 6/10\n",
            " - 11s - loss: 0.5502 - val_loss: 0.5447\n",
            "Epoch 7/10\n",
            " - 10s - loss: 0.5430 - val_loss: 0.5347\n",
            "Epoch 8/10\n",
            " - 10s - loss: 0.5364 - val_loss: 0.5345\n",
            "Epoch 9/10\n",
            " - 10s - loss: 0.5326 - val_loss: 0.5293\n",
            "Epoch 10/10\n",
            " - 11s - loss: 0.5289 - val_loss: 0.5271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_6 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_5/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_5/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  str(node.arguments) + '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QzPXJI29ZhAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "baeb92c8-5dff-4202-914e-90f9694b4dfe"
      },
      "cell_type": "code",
      "source": [
        "# Next: inference mode (sampling).\n",
        "# Here's the drill:\n",
        "# 1) encode input and retrieve initial decoder state\n",
        "# 2) run one step of decoder with this initial state\n",
        "# and a \"start of sequence\" token as target.\n",
        "# Output will be the next target token\n",
        "# 3) Repeat with the current target token and current states\n",
        "\n",
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mGX3YBoGaDSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "721ba2e1-10fb-4ab2-fc1d-f1f1c4eec838"
      },
      "cell_type": "code",
      "source": [
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rSaXCLDfaF1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "dbd49d7c-0d3f-497e-fc28-15852f8cf2f6"
      },
      "cell_type": "code",
      "source": [
        "# Reassign variables for convenience\n",
        "input_token_index = corpus_dict\n",
        "target_token_index = corpus_dict\n"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SMujy1T9aHya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e83974cf-3834-4e1c-8081-ee50fd6c85be"
      },
      "cell_type": "code",
      "source": [
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_s4CkbYzaJxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2f0309a2-f305-4b03-f4d6-ac4203ae3572"
      },
      "cell_type": "code",
      "source": [
        "# input and target use same vocab corpus. This time is for holdout (test) data\n",
        "test_num_encoder_tokens, test_num_decoder_tokens, test_max_encoder_seq_length, test_max_decoder_seq_length = get_array_specs(test_input_texts,test_target_texts, vocab, vocab)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8P5wWSvxbfNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63b0b475-ab38-4bc2-f2b8-aeb7a9cb6b26"
      },
      "cell_type": "code",
      "source": [
        "test_num_encoder_tokens"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "metadata": {
        "id": "AsUuqzSRbg_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7d26b1c-f8dc-46d4-be3f-f7b7918a1d22"
      },
      "cell_type": "code",
      "source": [
        "test_num_decoder_tokens"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "metadata": {
        "id": "D0RrxEWZbiFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f36f02b1-0f50-45e6-fd37-39e2b177c83a"
      },
      "cell_type": "code",
      "source": [
        "# create zero-hot holders for holdout data\n",
        "test_encoder_input_data_zero, test_decoder_input_data_zero, test_decoder_target_data_zero = create_zero_hot_holder(test_input_texts, test_max_encoder_seq_length, test_max_decoder_seq_length, test_num_encoder_tokens,test_num_decoder_tokens)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xnsRZrRgcN3s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b47125d4-4560-4b06-cccb-7344bdf8fa85"
      },
      "cell_type": "code",
      "source": [
        "# one-hot encode holdout data\n",
        "test_encoder_input_data, test_decoder_input_data, test_decoder_target_data = one_hot_encoding(test_encoder_input_data_zero, test_decoder_input_data_zero, test_decoder_target_data_zero, test_input_texts, test_target_texts, corpus_dict, corpus_dict)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "metadata": {
        "id": "km41yYE_coan",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73fdf5a6-c3bb-4723-8592-8c52105cead3"
      },
      "cell_type": "code",
      "source": [
        "test_encoder_input_data.shape"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 9, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "metadata": {
        "id": "3rJ5rEDFcwko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "49cd2913-c94a-46bd-bdfd-7171e172cb11"
      },
      "cell_type": "code",
      "source": [
        "# step 1. encoder model predicts states_value by using one-hot inputs.\n",
        "states_value = encoder_model.predict(test_encoder_input_data)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-J_3CMTndAy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ee79b63-3df1-4f24-d018-a68fd1384e67"
      },
      "cell_type": "code",
      "source": [
        "np.array(states_value).shape   # shape (state/value, observations, latent_dim)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 10001, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "metadata": {
        "id": "EmkVt-xndERH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bbb84dfb-6383-467c-b6f6-54ce139b1676"
      },
      "cell_type": "code",
      "source": [
        "# step 2. create a target_seq holder, with first position being initialized with the < start > token.\n",
        "\n",
        "# Generate empty target sequence of length 1.\n",
        "target_seq = np.zeros((test_encoder_input_data.shape[0], test_max_encoder_seq_length, num_decoder_tokens))\n",
        "# Populate the first character of target sequence with the start character.\n",
        "target_seq[:, 0, target_token_index['<start>']] = 1.\n"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aplbIucNdLqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8eeaa3b-ee3f-4d9a-a91c-3d8d84832d9b"
      },
      "cell_type": "code",
      "source": [
        "target_seq.shape"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 9, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "metadata": {
        "id": "0Gt8mcpOdbpQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "464560d4-b26d-4cfa-f7f4-0bc0f01bbe9a"
      },
      "cell_type": "code",
      "source": [
        "# step 3. decoder model can use target_seq holder and states_value to predict output_tokens, h, c.\n",
        "output_tokens, h, c = decoder_model.predict([target_seq] + states_value)"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HbTkSvY1eOSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3e3e51e-5a03-4446-cdf7-44a219e9a85e"
      },
      "cell_type": "code",
      "source": [
        "output_tokens.shape # (observations, max sequence length, onehot corpus size)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 9, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "metadata": {
        "id": "gvtseKKfeSL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3f5fb5c3-1f61-40df-e9ff-0cb89d64820b"
      },
      "cell_type": "code",
      "source": [
        "# step 4. decoder output_tokens go through argmax to get integer index.\n",
        "integer_list = output_tokens.argmax(axis=2)"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V6myyMrSeXTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9ace3a3-1e5a-4b8b-d89c-99de9dd9f1bb"
      },
      "cell_type": "code",
      "source": [
        "integer_list.shape"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "metadata": {
        "id": "inDT2i8leZ6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3b6a5bee-ffcc-4731-9997-0f07ae3ba80f"
      },
      "cell_type": "code",
      "source": [
        "# step 5. integer index is used to do reverse lookup to get to the corresponding word.\n",
        "translated_array = np.vectorize(reverse_input_char_index.get)(integer_list)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4mdsDG3Tec5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "038d89ca-e47b-4298-e806-1704ccb84749"
      },
      "cell_type": "code",
      "source": [
        "translated_array[:10]"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['CBS', 'CBS', 'CBS', 'CBS', 'CBS', 'CBS', 'visit', '<stop>',\n",
              "        '<stop>'],\n",
              "       ['NBC', 'NBC', 'NBC', 'NBC', '<stop>', '<stop>', '<stop>',\n",
              "        '<stop>', '<stop>'],\n",
              "       ['CBS', 'CBS', '<stop>', '<stop>', '<stop>', '<stop>', '<stop>',\n",
              "        '<stop>', '<stop>'],\n",
              "       ['NBC', 'NBC', '<stop>', '<stop>', '<stop>', '<stop>', '<stop>',\n",
              "        '<stop>', '<stop>'],\n",
              "       ['ABC', 'ABC', 'ABC', 'ABC', '<stop>', '<stop>', '<stop>',\n",
              "        '<stop>', '<stop>'],\n",
              "       ['NBC', 'NBC', '<stop>', '<stop>', '<stop>', '<stop>', '<stop>',\n",
              "        '<stop>', '<stop>'],\n",
              "       ['NBC', 'NBC', '<stop>', '<stop>', '<stop>', '<stop>', '<stop>',\n",
              "        '<stop>', '<stop>'],\n",
              "       ['NBC', 'NBC', '<stop>', '<stop>', '<stop>', '<stop>', '<stop>',\n",
              "        '<stop>', '<stop>'],\n",
              "       ['NBC', 'NBC', 'NBC', '<stop>', '<stop>', '<stop>', '<stop>',\n",
              "        '<stop>', '<stop>'],\n",
              "       ['visit', '<stop>', '<stop>', '<stop>', '<stop>', '<stop>',\n",
              "        '<stop>', '<stop>', '<stop>']], dtype='<U19')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "metadata": {
        "id": "UTqpFtoieit0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c145f8eb-ece3-43bc-8c9a-c6f8c8c77779"
      },
      "cell_type": "code",
      "source": [
        "translated_list = translated_array.tolist()"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TAYzuORlpqdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d231f1ef-209c-4fb0-f517-fd90ba56ce04"
      },
      "cell_type": "code",
      "source": [
        "translated_list[3]"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NBC',\n",
              " 'NBC',\n",
              " '<stop>',\n",
              " '<stop>',\n",
              " '<stop>',\n",
              " '<stop>',\n",
              " '<stop>',\n",
              " '<stop>',\n",
              " '<stop>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "metadata": {
        "id": "NJTncTAJpt2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "786555dd-35bf-4c9a-b84a-fac5db10fb0d"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "translated_list = translated_array.tolist()\n",
        "stop_word_list = ['<start>', '<stop>']\n",
        "translated_list[3]\n",
        "txt_holder = []\n",
        "a = [item for item in translated_list[3] if item not in stop_word_list]\n"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q1vH3_LDrebR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1d3c59f2-44e6-4b71-bdcf-4b4b8c70b08c"
      },
      "cell_type": "code",
      "source": [
        "def extract_items(translated_words_list, exclusion_word_list):\n",
        "  return [item for item in translated_words_list if item not in exclusion_word_list]"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wvN0Z3MnuFhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "af9b2fa8-3a75-47b2-96a6-464b0a5b9e52"
      },
      "cell_type": "code",
      "source": [
        "exclude_word_list = ['<start>', '<stop>']\n",
        "truncated_list = []\n",
        "for a_list in translated_list:\n",
        "  truncated_list.append(extract_items(a_list, exclude_word_list))"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_z5XG6lsTg0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c5598222-084b-401c-a8c1-8b92a522e46c"
      },
      "cell_type": "code",
      "source": [
        "predicted_list = []\n",
        "for small_list in truncated_list:\n",
        "    small_list_str = ' '.join(small_list)\n",
        "    predicted_list.append(small_list_str)"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YzGvK_DVPZVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4ea7ad07-7ec5-4777-e505-fe1b5f80a92f"
      },
      "cell_type": "code",
      "source": [
        "truncated_list[:10]"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['CBS', 'CBS', 'CBS', 'CBS', 'CBS', 'CBS', 'visit'],\n",
              " ['NBC', 'NBC', 'NBC', 'NBC'],\n",
              " ['CBS', 'CBS'],\n",
              " ['NBC', 'NBC'],\n",
              " ['ABC', 'ABC', 'ABC', 'ABC'],\n",
              " ['NBC', 'NBC'],\n",
              " ['NBC', 'NBC'],\n",
              " ['NBC', 'NBC'],\n",
              " ['NBC', 'NBC', 'NBC'],\n",
              " ['visit']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 300
        }
      ]
    },
    {
      "metadata": {
        "id": "PSvQiRMZSa30",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c5220352-ed18-4b2d-caef-980bf3cd815d"
      },
      "cell_type": "code",
      "source": [
        "predicted_list[:10]"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CBS CBS CBS CBS CBS CBS visit',\n",
              " 'NBC NBC NBC NBC',\n",
              " 'CBS CBS',\n",
              " 'NBC NBC',\n",
              " 'ABC ABC ABC ABC',\n",
              " 'NBC NBC',\n",
              " 'NBC NBC',\n",
              " 'NBC NBC',\n",
              " 'NBC NBC NBC',\n",
              " 'visit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 301
        }
      ]
    },
    {
      "metadata": {
        "id": "wr_LeeAuuVe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89b0f79d-dfb8-4f41-9a30-f5a665955827"
      },
      "cell_type": "code",
      "source": [
        "len(predicted_list)"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 302
        }
      ]
    },
    {
      "metadata": {
        "id": "LX8YhtQCuWwO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07b4b895-6920-417f-e99c-487a80b5e4f9"
      },
      "cell_type": "code",
      "source": [
        "len(test_target_texts)"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "metadata": {
        "id": "TvBDSzVeuXVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f54a18ae-c368-439d-912d-75d74c4e0928"
      },
      "cell_type": "code",
      "source": [
        "t1 = test_target_texts[:10]"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "metadata": {
        "id": "msgVxfCTJXAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1246ce7c-2527-41cc-8cf8-02872322dab3"
      },
      "cell_type": "code",
      "source": [
        "t1"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> web FX CBS USANetwork TBS <stop>',\n",
              " '<start> ESPN2 TNT visit <stop>',\n",
              " '<start> CBS ABC <stop>',\n",
              " '<start> ESPN2 <stop>',\n",
              " '<start> CBS ABC visit <stop>',\n",
              " '<start> NBC <stop>',\n",
              " '<start> TNT FOX <stop>',\n",
              " '<start> ABC <stop>',\n",
              " '<start> CW NBC Bravo <stop>',\n",
              " '<start> visit <stop>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    },
    {
      "metadata": {
        "id": "uhpL2cyouYoA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b30abe81-0ac5-4049-86f0-5e7d411273c5"
      },
      "cell_type": "code",
      "source": [
        "truth_holder = []\n",
        "for item in test_target_texts:\n",
        "    words = ''\n",
        "    for word in item.split(' '):\n",
        "        if word not in exclude_word_list:\n",
        "            words += ' '\n",
        "            words += word\n",
        "            \n",
        "    truth_holder.append(words) "
      ],
      "execution_count": 306,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OCLj2wvEuyLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c4e049c7-e3e6-4b8f-c420-a074527ab191"
      },
      "cell_type": "code",
      "source": [
        "truth_holder[:10]"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' web FX CBS USANetwork TBS',\n",
              " ' ESPN2 TNT visit',\n",
              " ' CBS ABC',\n",
              " ' ESPN2',\n",
              " ' CBS ABC visit',\n",
              " ' NBC',\n",
              " ' TNT FOX',\n",
              " ' ABC',\n",
              " ' CW NBC Bravo',\n",
              " ' visit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "metadata": {
        "id": "lhgr4vLAIdkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f8fe9330-5ff9-4858-d298-2f3e4551e5b6"
      },
      "cell_type": "code",
      "source": [
        "assert len(truth_holder) == len(predicted_list)"
      ],
      "execution_count": 309,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R-Ft7cTxM6fC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "033f4005-e8e6-46e1-e83f-ba361255242c"
      },
      "cell_type": "code",
      "source": [
        "s = len(predicted_list)\n",
        "holdout_results_holder = np.zeros((s, 3), dtype='int8') # columns will be actual, predicted, tabulation"
      ],
      "execution_count": 325,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OaE-aj2xNAHx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a6e61ca7-9c98-4adb-c762-a915126d4f83"
      },
      "cell_type": "code",
      "source": [
        "target_word = 'visit'\n",
        "for i, (truth_target_texts, predicted_sentence) in enumerate(zip(truth_holder, predicted_list)):\n",
        "      #print('i= %s, sentence = %s' % (i,predicted_sentence))\n",
        "  \n",
        "      truth_string = ''.join(truth_holder)\n",
        "      eval_string = ''.join(predicted_list)\n",
        "  \n",
        "      if target_word in truth_string:\n",
        "          holdout_results_holder[i][0] = 1\n",
        "    \n",
        "      if target_word in eval_string:\n",
        "          holdout_results_holder[i][1] = 1\n",
        "    \n",
        "      if holdout_results_holder[i][0] == holdout_results_holder[i][1]:\n",
        "          holdout_results_holder[i][-1] = 1"
      ],
      "execution_count": 312,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eahJf8-ihghM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "07abd405-e210-4ae3-946f-babca9092d79"
      },
      "cell_type": "code",
      "source": [
        "def compare_to_reference(truth_text_list, predicted_text_list, target_word):\n",
        "  # two lists has to have same number of elements.\n",
        "  # search for target word in each sentence list.\n",
        "  # last column is labeled if target_word's condition is same in both lists.\n",
        "  assert len(truth_text_list) == len(predicted_text_list)\n",
        "  \n",
        "  s = len(predicted_text_list)\n",
        "  holdout_results_holder = np.zeros((s, 3), dtype='int8') # columns are actual, predicted, tabulation\n",
        "\n",
        "\n",
        "  for i, (truth_target_texts, predicted_sentence) in enumerate(zip(truth_text_list, predicted_text_list)):\n",
        "      #print('i= %s, sentence = %s' % (i,predicted_sentence))\n",
        "  \n",
        "      truth_string = ''.join(truth_target_texts)\n",
        "      eval_string = ''.join(predicted_sentence)\n",
        "  \n",
        "      if target_word in truth_string:\n",
        "          holdout_results_holder[i][0] = 1\n",
        "    \n",
        "      if target_word in eval_string:\n",
        "          holdout_results_holder[i][1] = 1\n",
        "    \n",
        "      if holdout_results_holder[i][0] == holdout_results_holder[i][1]:\n",
        "          holdout_results_holder[i][-1] = 1\n",
        "  \n",
        "  return holdout_results_holder\n",
        "\n",
        "\n"
      ],
      "execution_count": 317,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dlKzOPmwNLd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c5d87276-c273-41de-e513-d5b04dbf1f64"
      },
      "cell_type": "code",
      "source": [
        "comp = compare_to_reference(truth_holder, predicted_list, 'visit')"
      ],
      "execution_count": 319,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BLG1lkJihST0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "89d2ce1a-9c59-48b8-b3f2-ad88fb768f56"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def print_classification_report(truth, predicted, target_names_list):\n",
        "    from sklearn.metrics import classification_report\n",
        "    # for printing performance of a classifier.\n",
        "    print(classification_report(truth, predicted, target_names = target_names_list))"
      ],
      "execution_count": 321,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3yj17uNxiUJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3e77dc34-1d93-47a9-a131-76f07ad38e22"
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data=comp, columns = [\"visited\", \"predicted\", \"tabulation\"])\n",
        "y_actu = pd.Series(df['visited'], name='Actual')\n",
        "y_pred = pd.Series(df['predicted'], name = 'Predicted')"
      ],
      "execution_count": 322,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tTqnPh4RifmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2b8f0d97-12ee-4c96-f849-a4f53b3363ba"
      },
      "cell_type": "code",
      "source": [
        "dl_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
        "dl_confusion"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6725</td>\n",
              "      <td>691</td>\n",
              "      <td>7416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1365</td>\n",
              "      <td>1220</td>\n",
              "      <td>2585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>8090</td>\n",
              "      <td>1911</td>\n",
              "      <td>10001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted     0     1    All\n",
              "Actual                      \n",
              "0          6725   691   7416\n",
              "1          1365  1220   2585\n",
              "All        8090  1911  10001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 323
        }
      ]
    },
    {
      "metadata": {
        "id": "AR8DVzyHih8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a2c47310-f46c-45f0-f117-cf0e4c197402"
      },
      "cell_type": "code",
      "source": [
        "predicted_results = y_pred.tolist()\n",
        "truth = y_actu.tolist()\n",
        "print_classification_report(truth, predicted_results, [ 'Actual 0', 'Actual 1'] )"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "   Actual 0       0.83      0.91      0.87      7416\n",
            "   Actual 1       0.64      0.47      0.54      2585\n",
            "\n",
            "avg / total       0.78      0.79      0.78     10001\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WVy5M7FHim3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75fb9f3b-3994-4459-f8b5-19075e059307"
      },
      "cell_type": "code",
      "source": [
        "type(dl_confusion)"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 326
        }
      ]
    },
    {
      "metadata": {
        "id": "LFa1j-zLyQs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2fe8bc38-5ea2-48e9-d942-e23aae2fbaf4"
      },
      "cell_type": "code",
      "source": [
        "dl_confusion.to_csv('/tmp/dl_confusion.csv', sep=',')"
      ],
      "execution_count": 328,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XwXp6bPazkt5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2c47cc08-d1c4-4391-8277-899fb08c3896"
      },
      "cell_type": "code",
      "source": [
        "! ls /tmp\n"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dl_confusion\t\t ed_lstm_20180708-200039  small_train_data.csv\r\n",
            "dl_confusion.csv\t ed_lstm_20180708-224041\r\n",
            "ed_lstm_20180708-194229  sample_data.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hW6KFoi0zpeM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1480bf22-7af1-4f96-e736-cfece2e924b9"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "rpt = classification_report(truth, predicted_results, target_names = [ 'Actual 0', 'Actual 1'])"
      ],
      "execution_count": 343,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D0oY0ycv1xhB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4aca5a4-a7c8-4e29-b36c-88e08eec67d3"
      },
      "cell_type": "code",
      "source": [
        "type(rpt)"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 344
        }
      ]
    },
    {
      "metadata": {
        "id": "WJ1BR4pjzuv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f458f1d0-3ef4-4d6b-c8c1-01f6194c8204"
      },
      "cell_type": "code",
      "source": [
        "rpt = print_classification_report(truth, predicted_results, [ 'Actual 0', 'Actual 1'] )"
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "   Actual 0       0.83      0.91      0.87      7416\n",
            "   Actual 1       0.64      0.47      0.54      2585\n",
            "\n",
            "avg / total       0.78      0.79      0.78     10001\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xtf0heqJz06T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6695d0b5-6c09-4a99-fef5-d7e791442c63"
      },
      "cell_type": "code",
      "source": [
        "with open(\"/tmp/classification_report.txt\", \"w\") as text_file:\n",
        "    text_file.write(\"%s\" % rpt)"
      ],
      "execution_count": 345,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xemK0JrYz9Q5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "38d19bec-08ca-4c7f-ac21-5314a0641aa7"
      },
      "cell_type": "code",
      "source": [
        "with open(\"/tmp/classification_report.txt\", 'r') as f:\n",
        "    rpt = f.read().split('\\n')"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q7MCmpKX0eQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a8fb0989-af96-4e32-935d-b0f6c05edd02"
      },
      "cell_type": "code",
      "source": [
        "rpt"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['             precision    recall  f1-score   support',\n",
              " '',\n",
              " '   Actual 0       0.83      0.91      0.87      7416',\n",
              " '   Actual 1       0.64      0.47      0.54      2585',\n",
              " '',\n",
              " 'avg / total       0.78      0.79      0.78     10001',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 347
        }
      ]
    },
    {
      "metadata": {
        "id": "OSovCN_61KrP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d000123-317c-476b-879c-726dbdec9cea"
      },
      "cell_type": "code",
      "source": [
        "type(rpt)"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        }
      ]
    },
    {
      "metadata": {
        "id": "O6XKJG151Lk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "adb641bf-3385-4864-c00a-86d00dc7e105"
      },
      "cell_type": "code",
      "source": [
        "len(rpt)"
      ],
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 349
        }
      ]
    },
    {
      "metadata": {
        "id": "pjdN9y_-3Rc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "86dc38d1-7aac-4cb5-a259-c33f146a0c3b"
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'col':rpt})"
      ],
      "execution_count": 350,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c3iaueK53kye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60ee184d-0ffd-49f8-b9f0-5737e4b967fe"
      },
      "cell_type": "code",
      "source": [
        "type(train_dat)"
      ],
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 352
        }
      ]
    },
    {
      "metadata": {
        "id": "TNcSBeZq3lZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "dc170bfb-190f-4f87-a9fb-28e97754109f"
      },
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "execution_count": 353,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4nQ-yBCH5Moy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3d1bee49-03b5-4cbb-a74d-f344439466b7"
      },
      "cell_type": "code",
      "source": [
        "with open('/tmp/train_dat.pickle', 'wb') as handle:\n",
        "    pickle.dump(train_dat, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 354,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qgOxUcOV5VUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "04f086ea-7d64-4bb2-8741-d29d91abb9bd"
      },
      "cell_type": "code",
      "source": [
        "with open('/tmp/train_dat.pickle', 'rb') as handle:\n",
        "    b = pickle.load(handle)"
      ],
      "execution_count": 355,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RGHAMy2q5aQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "cd26d836-69e0-4574-b1f3-cae9b6de2318"
      },
      "cell_type": "code",
      "source": [
        "with open('/tmp/validation_dat.pickle', 'wb') as handle:\n",
        "    pickle.dump(validation_dat, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 358,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KRkDBVrO5a4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f7c05bbf-ab41-44c6-bfc2-c035946cff66"
      },
      "cell_type": "code",
      "source": [
        "with open('/tmp/test_dat.pickle', 'wb') as handle:\n",
        "    pickle.dump(test_dat, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 359,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ak5vOPI95c3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7f722d34-c0ba-4f79-c279-799a1b0b4e74"
      },
      "cell_type": "code",
      "source": [
        "! ls /tmp ed_lstm_20180708-224041*"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'ed_lstm_20180708-224041*': No such file or directory\r\n",
            "/tmp:\r\n",
            "classification_report.txt  ed_lstm_20180708-224041  test_dat.pickle\r\n",
            "dl_confusion.csv\t   rpt.csv\t\t    train_dat.pickle\r\n",
            "ed_lstm_20180708-194229    sample_data.csv\t    validation_dat.pickle\r\n",
            "ed_lstm_20180708-200039    small_train_data.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wz_EMU8X6CVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "507b9424-a8d0-495d-c15c-b885d861a3c7"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json"
      ],
      "execution_count": 361,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mYuvIGiV6wbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e909175f-7cd1-4e69-84eb-3a204009f5f1"
      },
      "cell_type": "code",
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"/tmp/model_ed_lstm_20180708-224041.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/tmp/model_ed_lstm_20180708-224041.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_6 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_5/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_5/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  str(node.arguments) + '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1iHjM7B868lp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "30ae7a02-b56e-4668-8a7e-60dc047dabc5"
      },
      "cell_type": "code",
      "source": [
        "!ls -lrt /tmp"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 86428\r\n",
            "-rw-r--r-- 1 root root      399 Jul  8 19:40 sample_data.csv\r\n",
            "-rw-r--r-- 1 root root 27106008 Jul  8 19:42 ed_lstm_20180708-194229\r\n",
            "-rw-r--r-- 1 root root  7621848 Jul  8 20:03 ed_lstm_20180708-200039\r\n",
            "-rw-r--r-- 1 root root  7621888 Jul  8 22:42 ed_lstm_20180708-224041\r\n",
            "-rw-r--r-- 1 root root  1571369 Jul  9 01:24 small_train_data.csv\r\n",
            "-rw-r--r-- 1 root root       68 Jul  9 02:11 dl_confusion.csv\r\n",
            "-rw-r--r-- 1 root root        3 Jul  9 02:16 rpt.csv\r\n",
            "-rw-r--r-- 1 root root      214 Jul  9 02:24 classification_report.txt\r\n",
            "-rw-r--r-- 1 root root 25200150 Jul  9 02:36 train_dat.pickle\r\n",
            "-rw-r--r-- 1 root root  8400150 Jul  9 02:37 validation_dat.pickle\r\n",
            "-rw-r--r-- 1 root root  8400990 Jul  9 02:37 test_dat.pickle\r\n",
            "-rw-r--r-- 1 root root     2981 Jul  9 02:43 model_ed_lstm_20180708-224041.json\r\n",
            "-rw-r--r-- 1 root root  2547408 Jul  9 02:43 model_ed_lstm_20180708-224041.h5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rTTMMTmT7e44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XDx949PQ7CGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d722853b-906f-4335-83a8-90e294a00636"
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('/tmp/model_ed_lstm_20180708-224041.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/tmp/model_ed_lstm_20180708-224041.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oXKP0ybe7Wmx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73170f98-d3a8-451e-997f-9b44fdd3d069"
      },
      "cell_type": "code",
      "source": [
        "fdir = '/tmp/'\n",
        "fname = 'train_dat.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bRh_NrrF9hPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b126bc2d-844a-47dd-b199-511946e402f7"
      },
      "cell_type": "code",
      "source": [
        "fdir = '/tmp/'\n",
        "fname = 'validation_dat.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eIEmIwJ99zgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "97553d82-d14d-4da2-cc73-19eb9e7686d6"
      },
      "cell_type": "code",
      "source": [
        "fdir = '/tmp/'\n",
        "fname = 'test_dat.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PmTHtTXb98uz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "932ce9c1-d197-43e8-9c74-b2805d9cb5a6"
      },
      "cell_type": "code",
      "source": [
        "fdir = '/tmp/'\n",
        "fname = 'model_ed_lstm_20180708-224041.json'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HeEiHFVV-QQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6df8cd14-6ce9-470f-8c48-a03b738e6aa9"
      },
      "cell_type": "code",
      "source": [
        "fdir = '/tmp/'\n",
        "fname = 'model_ed_lstm_20180708-224041.h5'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sTP6D7Rj-xOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "bd425ef7-8512-48e9-b10b-52054bf87c7a"
      },
      "cell_type": "code",
      "source": [
        "test_encoder_input_data"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 373
        }
      ]
    },
    {
      "metadata": {
        "id": "7PXtD82mAQpv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c15668e5-e7ef-45e7-cc19-ce2e62211bac"
      },
      "cell_type": "code",
      "source": [
        "with open('/tmp/test_encoder_input_data.pickle', 'wb') as handle:\n",
        "    pickle.dump(test_encoder_input_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "fdir = '/tmp/'\n",
        "fname = 'test_encoder_input_data.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DcLb0JjYAefb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "14537db5-84d2-4e70-f209-939e4c717352"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "with open('/tmp/states_value.pickle', 'wb') as handle:\n",
        "    pickle.dump(states_value, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "fdir = '/tmp/'\n",
        "fname = 'states_value.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d1vyq1a_A_BQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7cbb7085-5a4f-4b3a-931e-cec10d511a52"
      },
      "cell_type": "code",
      "source": [
        "#reverse_input_char_index\n",
        "\n",
        "with open('/tmp/reverse_input_char_index.pickle', 'wb') as handle:\n",
        "    pickle.dump(reverse_input_char_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "fdir = '/tmp/'\n",
        "fname = 'reverse_input_char_index.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 386,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E3zxE8s9CXkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b11052cd-a156-4c30-a43b-5f75d474d3fb"
      },
      "cell_type": "code",
      "source": [
        "#reverse_target_char_index\n",
        "with open('/tmp/reverse_target_char_index.pickle', 'wb') as handle:\n",
        "    pickle.dump(reverse_target_char_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "fdir = '/tmp/'\n",
        "fname = 'reverse_target_char_index.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4sV9T66NCeq2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e6bd164c-e4e8-413a-fdd5-fe6b6fe0d895"
      },
      "cell_type": "code",
      "source": [
        "# target_seq\n",
        "with open('/tmp/target_seq.pickle', 'wb') as handle:\n",
        "    pickle.dump(target_seq, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "fdir = '/tmp/'\n",
        "fname = 'target_seq.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yjdYqmGGC3yL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "98ea0c12-1fd5-4f96-bfc2-4b2740d3e56c"
      },
      "cell_type": "code",
      "source": [
        "#output_tokens, h, c these are from output of decoder model predicting test data.\n",
        "with open('/tmp/output_tokens.pickle', 'wb') as handle:\n",
        "    pickle.dump(output_tokens, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "fdir = '/tmp/'\n",
        "fname = 'output_tokens.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uKMVDVSxDHjt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "363fb95b-2828-4a71-d2df-5acbb8818a6a"
      },
      "cell_type": "code",
      "source": [
        "with open('/tmp/h.pickle', 'wb') as handle:\n",
        "    pickle.dump(h, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "fdir = '/tmp/'\n",
        "fname = 'h.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BqdIGCNxDN4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65b8f35a-fcdc-4784-9e00-d4e10b48ea29"
      },
      "cell_type": "code",
      "source": [
        "with open('/tmp/c.pickle', 'wb') as handle:\n",
        "    pickle.dump(c, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "\n",
        "fdir = '/tmp/'\n",
        "fname = 'c.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wq4wXs70DQdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f36ac824-6854-4d7e-f2ea-9d2d15ed9f83"
      },
      "cell_type": "code",
      "source": [
        "# truth_holder, predicted_list\n",
        "with open('/tmp/truth_holder.pickle', 'wb') as handle:\n",
        "    pickle.dump(truth_holder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "\n",
        "fdir = '/tmp/'\n",
        "fname = 'truth_holder.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qRN81WgqGkjS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eaa6597b-0763-4d5a-d854-162b3c4df7cf"
      },
      "cell_type": "code",
      "source": [
        "# predicted_list\n",
        "with open('/tmp/predicted_list.pickle', 'wb') as handle:\n",
        "    pickle.dump(predicted_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "\n",
        "fdir = '/tmp/'\n",
        "fname = 'predicted_list.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XStpoDm8GtIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "06e2ee50-9ade-4e15-da6b-6198979b9a43"
      },
      "cell_type": "code",
      "source": [
        "#comp\n",
        "\n",
        "\n",
        "with open('/tmp/comp.pickle', 'wb') as handle:\n",
        "    pickle.dump(comp, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "\n",
        "fdir = '/tmp/'\n",
        "fname = 'comp.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gx8Cpe1EHqIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "44efcac0-09aa-424e-a4b7-e198af014e12"
      },
      "cell_type": "code",
      "source": [
        "! ls -lrt /tmp"
      ],
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 191496\r\n",
            "-rw-r--r-- 1 root root      399 Jul  8 19:40 sample_data.csv\r\n",
            "-rw-r--r-- 1 root root 27106008 Jul  8 19:42 ed_lstm_20180708-194229\r\n",
            "-rw-r--r-- 1 root root  7621848 Jul  8 20:03 ed_lstm_20180708-200039\r\n",
            "-rw-r--r-- 1 root root  7621888 Jul  8 22:42 ed_lstm_20180708-224041\r\n",
            "-rw-r--r-- 1 root root  1571369 Jul  9 01:24 small_train_data.csv\r\n",
            "-rw-r--r-- 1 root root       68 Jul  9 02:11 dl_confusion.csv\r\n",
            "-rw-r--r-- 1 root root        3 Jul  9 02:16 rpt.csv\r\n",
            "-rw-r--r-- 1 root root      214 Jul  9 02:24 classification_report.txt\r\n",
            "-rw-r--r-- 1 root root 25200150 Jul  9 02:36 train_dat.pickle\r\n",
            "-rw-r--r-- 1 root root  8400150 Jul  9 02:37 validation_dat.pickle\r\n",
            "-rw-r--r-- 1 root root  8400990 Jul  9 02:37 test_dat.pickle\r\n",
            "-rw-r--r-- 1 root root     2981 Jul  9 02:43 model_ed_lstm_20180708-224041.json\r\n",
            "-rw-r--r-- 1 root root  2547408 Jul  9 02:43 model_ed_lstm_20180708-224041.h5\r\n",
            "-rw-r--r-- 1 root root 16561813 Jul  9 03:20 test_encoder_input_data.pickle\r\n",
            "-rw-r--r-- 1 root root 20482254 Jul  9 03:20 states_value.pickle\r\n",
            "-rw-r--r-- 1 root root      577 Jul  9 03:21 reverse_input_char_index.pickle\r\n",
            "-rw-r--r-- 1 root root      577 Jul  9 03:21 reverse_target_char_index.pickle\r\n",
            "-rw-r--r-- 1 root root 33123469 Jul  9 03:22 target_seq.pickle\r\n",
            "-rw-r--r-- 1 root root 16561813 Jul  9 03:22 output_tokens.pickle\r\n",
            "-rw-r--r-- 1 root root 10241180 Jul  9 03:22 h.pickle\r\n",
            "-rw-r--r-- 1 root root 10241180 Jul  9 03:23 c.pickle\r\n",
            "-rw-r--r-- 1 root root        0 Jul  9 03:33 truth_text_list.pickle\r\n",
            "-rw-r--r-- 1 root root   169249 Jul  9 03:35 truth_holder.pickle\r\n",
            "-rw-r--r-- 1 root root   148331 Jul  9 03:36 predicted_list.pickle\r\n",
            "-rw-r--r-- 1 root root    30158 Jul  9 03:38 comp.pickle\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BvVrGXCTUf8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0470fe76-c861-4d6c-9353-3dfb8a71989c"
      },
      "cell_type": "code",
      "source": [
        "#ed_lstm_20180708-224041\n",
        "\n",
        "with open('/tmp/ed_lstm_20180708-224041.pickle', 'wb') as handle:\n",
        "    pickle.dump(comp, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "\n",
        "fdir = '/tmp/'\n",
        "fname = 'ed_lstm_20180708-224041.pickle'\n",
        "full_fname = fdir+fname\n",
        "#write file to bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload(full_fname, \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket='bucket-kctung75034-1', \n",
        "                                       name=fname,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload complete\n",
            "https://console.cloud.google.com/storage/browser?project=project1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CevatGsgVnHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}